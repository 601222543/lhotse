#!/usr/bin/env python
"""
Use this script like:

$ lhotse --help
$ lhotse make-feats --help
$ lhotse make-feats --compressed audio_manifest.yml mfcc_dir/
$ lhotse write-default-feature-config feat-conf.yml
$ lhotse convert-kaldi data/train/ 16000 train_manifests/
$ lhotse split 3 audio.yml split_manifests/
$ lhotse combine feature.1.yml feature.2.yml combined_feature.yml
"""
import random
from pathlib import Path
from typing import Optional, Tuple

import click
import numpy as np

from lhotse.audio import AudioSet
from lhotse.cut import CutSet, make_trivial_cut_set
from lhotse.features import FeatureExtractor, FeatureSetBuilder, FeatureSet
from lhotse.kaldi import load_kaldi_data_dir
from lhotse.manipulation import (
    split as split_manifest,
    combine as combine_manifests,
    load_manifest
)
from lhotse.supervision import SupervisionSet
from lhotse.utils import Pathlike


@click.group()
def cli():
    """
    The shell entry point to Lhotse, a tool and a library for audio data manipulation in high altitudes.
    """
    pass


@cli.command()
@click.argument('data_dir', type=click.Path(exists=True, file_okay=False))
@click.argument('sampling_rate', type=int)
@click.argument('manifest_dir', type=click.Path())
def convert_kaldi(data_dir: Pathlike, sampling_rate: int, manifest_dir: Pathlike):
    """
    Convert a Kaldi data dir DATA_DIR into a directory MANIFEST_DIR of lhotse manifests. Ignores feats.scp.
    The SAMPLING_RATE has to be explicitly specified as it is not available to read from DATA_DIR.
    """
    audio_set, maybe_supervision_set = load_kaldi_data_dir(path=data_dir, sampling_rate=sampling_rate)
    manifest_dir = Path(manifest_dir)
    manifest_dir.mkdir(parents=True, exist_ok=True)
    audio_set.to_yaml(manifest_dir / 'audio.yml')
    if maybe_supervision_set is not None:
        maybe_supervision_set.to_yaml(manifest_dir / 'supervision.yml')


@cli.command()
@click.argument('num_splits', type=int)
@click.argument('manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('output_dir', type=click.Path())
def split(num_splits: int, manifest: Pathlike, output_dir: Pathlike):
    """Load MANIFEST, split it into NUM_SPLITS equal parts and save as separate manifests in OUTPUT_DIR. """
    output_dir = Path(output_dir)
    manifest = Path(manifest)
    data_set = load_manifest(manifest)
    parts = split_manifest(manifest=data_set, num_splits=num_splits)
    output_dir.mkdir(parents=True, exist_ok=True)
    for idx, part in enumerate(parts):
        part.to_yaml(output_dir / f'{manifest.stem}.{idx + 1}.yml')


@cli.command()
@click.argument('manifests', nargs=-1, type=click.Path(exists=True, dir_okay=False))
@click.argument('output_manifest', type=click.Path())
def combine(manifests: Pathlike, output_manifest: Pathlike):
    """Load MANIFESTS, combine them into a single one, and write it to OUTPUT_MANIFEST."""
    data_set = combine_manifests(*[load_manifest(m) for m in manifests])
    data_set.to_yaml(output_manifest)


@cli.command()
@click.argument('output_config', type=click.Path())
def write_default_feature_config(output_config):
    """Save a default feature extraction config to OUTPUT_CONFIG."""
    FeatureExtractor().to_yaml(output_config)


@cli.command()
@click.argument('audio_manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('output_dir', type=click.Path())
@click.option('-s', '--segmentation-manifest', type=click.Path(exists=True, dir_okay=False),
              help='Optional manifest specifying the regions, for which features are to be extracted. '
                   'When not specified, features will be extracted for the entire recording. '
                   'Supervision manifest can be used here.')
@click.option('-a', '--augmentation-manifest', type=click.Path(exists=True, dir_okay=False),
              help='Optional manifest specifying augmentation transforms that can be applied to recordings.')
@click.option('-f', '--feature-manifest', type=click.Path(exists=True, dir_okay=False),
              help='Optional manifest specifying feature extractor configuration.')
@click.option('--compressed/--not-compressed', default=True, help='Enable/disable lilcom for features compression.')
@click.option('-t', '--lilcom-tick-power', type=int, default=-8,
              help='Determines the compression accuracy; '
                   'the input will be compressed to integer multiples of 2^tick_power')
@click.option('-j', '--num-jobs', type=int, default=1, help='Number of parallel processes.')
def make_feats(
        audio_manifest: Pathlike,
        output_dir: Pathlike,
        segmentation_manifest: Optional[Pathlike],
        # TODO: augmentation manifest should specify a number of transforms and probability of their application
        # e.g.:
        # "add_noise", "prob": 0.5, "noise_recordings": ["path1.wav", "path2.wav"]
        # "reverberate", "prob": 0.2, "rirs": ["rir1.wav", "rir2.wav"] (or however the RIRs are stored like... can be params for simulation)
        augmentation_manifest: Optional[Pathlike],
        feature_manifest: Optional[Pathlike],
        compressed: bool,
        lilcom_tick_power: int,
        num_jobs: int
):
    """
    Extract features for recordings in a given AUDIO_MANIFEST. The features are stored in OUTPUT_DIR,
    with one file per recording (or segment).
    """
    audio_set = AudioSet.from_yaml(audio_manifest)

    feature_extractor = (FeatureExtractor.from_yaml(feature_manifest)
                         if feature_manifest is not None else FeatureExtractor())

    # TODO: to be used (actually, only the segmentation info will be used, and all supervision info will be ignored)
    supervision_set = (SupervisionSet.from_yaml(segmentation_manifest)
                       if segmentation_manifest is not None else None)

    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)

    feature_set_builder = FeatureSetBuilder(
        feature_extractor=feature_extractor,
        output_dir=output_dir,
        augmentation_manifest=augmentation_manifest
    )
    feature_set_builder.process_and_store_recordings(
        recordings=audio_set,
        segmentation=None,  # TODO: implement and use
        compressed=compressed,
        lilcom_tick_power=lilcom_tick_power,
        num_jobs=num_jobs
    )


@cli.command()
@click.argument('supervision_manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('feature_manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('output_cut_manifest', type=click.Path())
def make_trivial_cuts(
        supervision_manifest: Pathlike,
        feature_manifest: Pathlike,
        output_cut_manifest: Pathlike,
):
    """
    Create a CutSet stored in OUTPUT_CUT_MANIFEST that contains supervision regions from SUPERVISION_MANIFEST
    and features supplied by FEATURE_MANIFEST. This is the most trivial way to create Cuts.
    """
    supervision_set = SupervisionSet.from_yaml(supervision_manifest)
    feature_set = FeatureSet.from_yaml(feature_manifest)
    cut_set = make_trivial_cut_set(supervision_set=supervision_set, feature_set=feature_set)
    cut_set.to_yaml(output_cut_manifest)


@cli.command()
@click.argument('supervision_manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('feature_manifest', type=click.Path(exists=True, dir_okay=False))
@click.argument('output_cut_manifest', type=click.Path())
@click.option('-r', '--random-seed', default=42, type=int, help='Random seed value.')
@click.option('-s', '--snr-range', type=(float, float), default=(20, 20),
              help='Range of SNR values (in dB) that will be uniformly sampled in order to overlay the signals.')
@click.option('-o', '--offset-range', type=(float, float), default=(0.5, 0.5),
              help='Range of relative offset values (0 - 1), which will offset the "right" signal by this many times '
                   'the duration of the "left" signal. It is uniformly sampled for each overlay operation.')
def make_overlayed_cuts(
        supervision_manifest: Pathlike,
        feature_manifest: Pathlike,
        output_cut_manifest: Pathlike,
        random_seed: int,
        snr_range: Tuple[float, float],
        offset_range: Tuple[float, float]
):
    """
    Create a CutSet stored in OUTPUT_CUT_MANIFEST that contains supervision regions from SUPERVISION_MANIFEST
    and features supplied by FEATURE_MANIFEST. It first creates a trivial CutSet, splits it into two equal parts,
    and overlays the signals features to create a mix. The parameters of the mix are controlled via CLI options.
    """
    random.seed(random_seed)
    np.random.seed(random_seed)

    supervision_set = SupervisionSet.from_yaml(supervision_manifest)
    feature_set = FeatureSet.from_yaml(feature_manifest)

    source_cut_set = make_trivial_cut_set(supervision_set=supervision_set, feature_set=feature_set)
    left_cuts, right_cuts = split_manifest(source_cut_set, num_splits=2, randomize=True)

    snrs = np.random.uniform(*snr_range, size=len(left_cuts)).tolist()
    relative_offsets = np.random.uniform(*offset_range, size=len(left_cuts)).tolist()

    cuts = (
        left_cut.overlay(
            right_cut,
            offset_other_by=left_cut.duration * relative_offset,
            snr=snr
        )
        for left_cut, right_cut, snr, relative_offset in zip(left_cuts, right_cuts, snrs, relative_offsets)
    )

    # Make the overlayed cut set contain both the overlayed cuts and the source cuts
    overlayed_cut_set = CutSet(cuts={cut.id: cut for cut in cuts}) + source_cut_set
    overlayed_cut_set.to_yaml(output_cut_manifest)


if __name__ == '__main__':
    cli()
